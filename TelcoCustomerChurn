import pandas as pd
telco_churn = pd.read_csv("Telco-Customer-Churn.csv")
print(telco_churn)

#Görev 1 :
#Adım 1: Numerik ve kategorik değişkenleri yakalayınız.
numerical_columns = telco_churn.select_dtypes(include=['int64', 'float64']).columns
categorical_columns = telco_churn.select_dtypes(include=['object']).columns

print(f"Numerik Değişkenler: {numerical_columns}")
print(f"Kategorik Değişkenler: {categorical_columns}")

#Adım 2: Gerekli düzenlemeleri yapınız. (Tip hatası olan değişkenler gibi)

# TotalCharges sütununu sayısal (float) veri tipine dönüştürmek için:
# Öncelikle boş değerleri (NaN) kontrol edelim
telco_churn['TotalCharges'] = pd.to_numeric(telco_churn['TotalCharges'], errors='coerce')

# SeniorCitizen sütununu integer veri tipine dönüştürmek için:
telco_churn['SeniorCitizen'] = telco_churn['SeniorCitizen'].astype('int64')

# Kategorik sütunları kontrol edelim
# Örneğin, "Churn" sütununda 'Yes' ve 'No' değerlerini kontrol edelim
telco_churn['Churn'] = telco_churn['Churn'].map({'Yes': 1, 'No': 0})

# Eksik verileri kontrol edelim
print(telco_churn.isnull().sum())

# Düzeltmelerin sonrasında veri tiplerini kontrol edelim
print(telco_churn.dtypes)

print(telco_churn.head()) # verinin en son hali

#Adım 3: Numerik ve kategorik değişkenlerin veri içindeki dağılımını gözlemleyiniz.
import matplotlib.pyplot as plt
import seaborn as sns

#1 Numerik Değişkenlerin Dağılımı
numerical_columns = telco_churn.select_dtypes(include=['int64', 'float64']).columns

# Numerik değişkenlerin istatistiksel özeti
print(telco_churn[numerical_columns].describe())

# Numerik değişkenler için histogramlar
telco_churn[numerical_columns].hist(bins=20, figsize=(12, 10))
plt.suptitle('Numerik Değişkenlerin Dağılımı')
plt.show()

#2 Kategorik Değişkenlerin Dağılımı
categorical_columns = telco_churn.select_dtypes(include=['object']).columns

# Kategorik değişkenlerin frekans dağılımı
for column in categorical_columns:
    print(f"--- {column} ---")
    print(telco_churn[column].value_counts())
    print("\n")

# Kategorik değişkenler için bar grafikleri
plt.figure(figsize=(12, 8))
for i, column in enumerate(categorical_columns, 1):
    plt.subplot(3, 5, i)  # 3 satır 5 sütunluk bir düzen
    sns.countplot(x=column, data=telco_churn)
    plt.title(f"{column} Dağılımı")
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#Adım 4: Kategorik değişkenler ile hedef değişken incelemesini yapınız.
# Kategorik değişkenler
categorical_columns = telco_churn.select_dtypes(include=['object']).columns

# Churn sütunu 0 ve 1 olarak kodlandıysa, Churn'un kategorik olduğunu doğrulamak
telco_churn['Churn'] = telco_churn['Churn'].map({'Yes': 1, 'No': 0})

# Kategorik değişkenlerin Churn ile ilişkisini inceleyelim
plt.figure(figsize=(15, 12))
for i, column in enumerate(categorical_columns, 1):
    if column != 'Churn':  # Churn zaten hedef değişken olduğu için burada tekrar göstermiyoruz
        plt.subplot(3, 5, i)  # 3 satır 5 sütunluk bir düzen
        sns.countplot(x=column, hue='Churn', data=telco_churn)
        plt.title(f"{column} ile Churn Dağılımı")
        plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Kategorik değişkenlerin Churn ile ilişkisini sayısal olarak görmek için
for column in categorical_columns:
    if column != 'Churn':  # Churn zaten hedef değişken olduğu için burada tekrar göstermiyoruz
        print(f"--- {column} ile Churn ---")
        print(telco_churn.groupby(column)['Churn'].value_counts(normalize=True))
        print("\n")

#Adım 5: Aykırı gözlem var mı inceleyiniz.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Numerik değişkenler
numerical_columns = telco_churn.select_dtypes(include=['int64', 'float64']).columns

#IQR Yöntemi ile Aykırı Değerleri Tespit Etme
for column in numerical_columns:
    Q1 = telco_churn[column].quantile(0.25)
    Q3 = telco_churn[column].quantile(0.75)
    IQR = Q3 - Q1

    # Aykırı değerler: Q1 - 1.5*IQR ve Q3 + 1.5*IQR dışındaki değerler
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Aykırı değerlerin sayısını alalım
    outliers = telco_churn[(telco_churn[column] < lower_bound) | (telco_churn[column] > upper_bound)]
    print(f"Aykırı değerler için {column} sütununda {len(outliers)} gözlem var.")

# Z-skoru ile Aykırı Değerleri Tespit Etme
from scipy import stats

z_scores = np.abs(stats.zscore(telco_churn[numerical_columns]))
outliers_z = (z_scores > 3).sum(axis=0)

for i, column in enumerate(numerical_columns):
    print(f"{column} sütununda Z-skoru ile {outliers_z[i]} aykırı değer var.")

#Adım 6: Eksik gözlem var mı inceleyiniz.

#Eksik Değerlerin Sayısı
missing_data = telco_churn.isnull().sum()
print("Eksik Değerlerin Sayısı:\n", missing_data)

# Eksik Verilerin Oranı
missing_percentage = (telco_churn.isnull().mean() * 100)
print("\nEksik Değerlerin Yüzdesi:\n", missing_percentage)

# Eksik Verilerin Görselleştirilmesi
plt.figure(figsize=(12, 8))
sns.heatmap(telco_churn.isnull(), cbar=False, cmap='viridis')
plt.title('Eksik Değerlerin Görselleştirilmesi')
plt.show()

# Hangi Değişkenlerde Eksik Veri Olduğunu Kontrol Etme
# Değişkenlerdeki eksik veri oranını listeleyelim
missing_columns = missing_data[missing_data > 0]
print("\nEksik Değer Bulunan Değişkenler ve Sayıları:\n", missing_columns)


##################################################
#Görev 2 : Feature Engineering

#Adım 1: Eksik ve aykırı gözlemler için gerekli işlemleri yapınız.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Eksik Gözlemlerle İlgili İşlemler

# Numerik ve kategorik değişkenler
numerical_columns = telco_churn.select_dtypes(include=['int64', 'float64']).columns
categorical_columns = telco_churn.select_dtypes(include=['object']).columns

# Numerik değişkenlerde eksik verileri medyan ile dolduralım
for column in numerical_columns:
    telco_churn[column].fillna(telco_churn[column].median(), inplace=True)

# Kategorik değişkenlerde eksik verileri mod ile dolduralım
for column in categorical_columns:
    telco_churn[column].fillna(telco_churn[column].mode()[0], inplace=True)

# Aykırı Gözlemlerle İlgili İşlemler

# Aykırı gözlemleri tespit etmek için IQR yöntemini kullanıyoruz
for column in numerical_columns:
    Q1 = telco_churn[column].quantile(0.25)
    Q3 = telco_churn[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Aykırı değerler: IQR dışındaki değerler
    telco_churn[column] = np.where(telco_churn[column] < lower_bound, lower_bound,
                                   np.where(telco_churn[column] > upper_bound, upper_bound, telco_churn[column]))

# Eksik ve Aykırı Gözlemleri Kontrol Edelim

# Eksik verileri kontrol edelim
missing_data = telco_churn.isnull().sum()
missing_percentage = (telco_churn.isnull().mean() * 100)

print("Eksik Değerlerin Sayısı:\n", missing_data)
print("\nEksik Değerlerin Yüzdesi:\n", missing_percentage)

# Aykırı değerlerin son durumunu kontrol edelim
for column in numerical_columns:
    Q1 = telco_churn[column].quantile(0.25)
    Q3 = telco_churn[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers_after = len(telco_churn[(telco_churn[column] < lower_bound) | (telco_churn[column] > upper_bound)])
    print(f"{column} sütununda kalan aykırı değer sayısı: {outliers_after}")

#Adım 2: Yeni değişkenler oluşturunuz.

# "TotalCharges" değişkenini sayısal hale getirelim
telco_churn['TotalCharges'] = pd.to_numeric(telco_churn['TotalCharges'], errors='coerce')

# Yeni Değişken: Yıllık Ücretler
telco_churn['AnnualCharges'] = telco_churn['MonthlyCharges'] * 12

#  Yeni Değişken: SeniorCitizen ve Churn Durumuna Göre Yeni Kategori
telco_churn['SeniorChurn'] = telco_churn.apply(lambda row: 1 if row['SeniorCitizen'] == 1 and row['Churn'] == 'Yes' else 0, axis=1)

# Yeni Değişken: Kişisel Hedef - Aylık Ortalama Harcama
telco_churn['AverageMonthlySpend'] = telco_churn['TotalCharges'] / telco_churn['tenure']

# Yeni Değişken: "Senior" Kategorisi
telco_churn['Senior'] = telco_churn['SeniorCitizen'].apply(lambda x: 'Yes' if x == 1 else 'No')

# Değişkenlerin son haliyle veri setini görüntüleyelim
print(telco_churn[['customerID', 'MonthlyCharges', 'TotalCharges', 'AnnualCharges', 'SeniorChurn', 'AverageMonthlySpend', 'Senior']].head())

#Adım 3: Encoding işlemlerini gerçekleştiriniz.

# Label Encoding: 'Senior' (Yaşlı) değişkeni
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
telco_churn['Senior'] = label_encoder.fit_transform(telco_churn['Senior'])

# One-Hot Encoding: 'gender', 'Churn' değişkenleri için
telco_churn = pd.get_dummies(telco_churn, columns=['gender', 'Churn'], drop_first=True)

# Ordinal Encoding: 'Contract' değişkeni için (Örneğin, sözleşme türüne göre sıralama)
contract_order = {'Month-to-month': 1, 'One year': 2, 'Two year': 3}
telco_churn['Contract'] = telco_churn['Contract'].map(contract_order)

# Değişkenlerin son haliyle veri setini görüntüleyelim
print(telco_churn[['customerID', 'SeniorCitizen', 'gender_Male', 'Churn_Yes', 'Contract']].head())

#Adım 4: Numerik değişkenler için standartlaştırma yapınız
import pandas as pd
from sklearn.preprocessing import StandardScaler
numerical_columns = ['MonthlyCharges', 'TotalCharges', 'tenure'] #numerik değişkenleri seçtik.

# Standartlaştırıcıyı oluşturun
scaler = StandardScaler()

# Seçilen numerik değişkenler üzerinde standartlaştırma işlemi yapın
telco_churn[numerical_columns] = scaler.fit_transform(telco_churn[numerical_columns])
print(telco_churn[numerical_columns].head())

######################################################
#Görev 3 : Modelleme

#Adım 1: Sınıflandırma algoritmaları ile modeller kurup, accuracy skorlarını inceleyip. En iyi 4 modeli seçiniz.
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
# Verinin sütun adlarını kontrol edelim
print(telco_churn.columns)

X = telco_churn.drop(columns=['customerID', "Churn_Yes"])
y = telco_churn['Churn_Yes']  # 'Churn_Yes' (1: Ayrılma, 0: Kalma)

# Eğitim ve test verisi olarak ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Modelleri tanımlayalım
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'SVM': SVC(),
    'KNN': KNeighborsClassifier()
}


from sklearn.preprocessing import LabelEncoder

# LabelEncoder ile kategorik verileri sayısal verilere dönüştürme
label_encoder = LabelEncoder()

# 'Churn' sütununu sayısal hale getiriyoruz
telco_churn['Churn_Yes'] = label_encoder.fit_transform(telco_churn['Churn'])  # 'Yes' -> 1, 'No' -> 0

# Modellerin accuracy skorlarını hesapla ve bir sözlükte sakla
accuracy_scores = {}

for model_name, model in models.items():
    # Modeli eğit
    model.fit(X_train, y_train)

    # Tahmin yap
    y_pred = model.predict(X_test)

    # Accuracy skorunu hesapla
    accuracy = accuracy_score(y_test, y_pred)

    # Skoru sakla
    accuracy_scores[model_name] = accuracy

# Accuracy skorlarını sıralı şekilde yazdırma
sorted_accuracy_scores = sorted(accuracy_scores.items(), key=lambda x: x[1], reverse=True)
print("Accuracy Skorları:")
for model_name, accuracy in sorted_accuracy_scores:
    print(f"{model_name}: {accuracy:.4f}")

#Adım 2: Seçtiğiniz modeller ile hiperparametre optimizasyonu gerçekleştirin ve bulduğunuz hiparparametreler ile modeli tekrar kurunuz
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd

# Bağımsız ve bağımlı değişkenleri belirleme
X = telco_churn.drop(columns=['customerID', 'Churn_Yes'])
y = telco_churn['Churn_Yes']

# Eğitim ve test verisi olarak ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Veriyi ölçeklendirme (Bazı modeller için önemli)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost
from sklearn.metrics import accuracy_score
# Logistic Regression
log_reg_params = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'saga']
}

log_reg = LogisticRegression(max_iter=1000)
log_reg_grid = GridSearchCV(log_reg, log_reg_params, cv=5, scoring='accuracy', n_jobs=-1)
log_reg_grid.fit(X_train, y_train)
best_log_reg = log_reg_grid.best_estimator_

# Random Forest
rf_params = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}

rf = RandomForestClassifier(random_state=42)
rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy', n_jobs=-1)
rf_grid.fit(X_train, y_train)
best_rf = rf_grid.best_estimator_

# Support Vector Machine (SVM)
svm_params = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto']
}

svm = SVC()
svm_grid = GridSearchCV(svm, svm_params, cv=5, scoring='accuracy', n_jobs=-1)
svm_grid.fit(X_train, y_train)
best_svm = svm_grid.best_estimator_
models = {
    "Logistic Regression": best_log_reg,
    "Random Forest": best_rf,
    "XGBoost": best_xgb,
    "SVM": best_svm
}

for model_name, model in models.items():
    model.fit(X_train, y_train)  # Modeli eğitme
    y_pred = model.predict(X_test)  # Test verisi ile tahmin yapma
    accuracy = accuracy_score(y_test, y_pred)  # Doğruluk skoru hesaplama
    print(f"{model_name} Accuracy: {accuracy:.4f}")
